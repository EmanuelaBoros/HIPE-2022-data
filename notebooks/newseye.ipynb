{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List, Dict\n",
    "from hipe_commons.helpers.tsv import parse_tsv, ENTITY_TYPES, HipeDocument, HipeEntity\n",
    "from hipe_commons.stats import describe_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_entities(documents: List[HipeDocument]) -> Dict[str, List[HipeEntity]]:\n",
    "    \"\"\"Simple function to gather all entities from documents in a dataset, divided by type.\n",
    "\n",
    "    :param documents: Input documents in HIPE format\n",
    "    :type documents: List[HipeDocument]\n",
    "    :return: A list of `HipeEntity` objects\n",
    "    :rtype: Dict[str, List[HipeEntity]]\n",
    "    \"\"\"\n",
    "    all_entities = {}\n",
    "\n",
    "    for doc in ajmc_sample_en_docs:\n",
    "        for e_type in ENTITY_TYPES:\n",
    "            \n",
    "            if e_type in doc.entities:\n",
    "\n",
    "                if e_type not in all_entities:\n",
    "                    all_entities[e_type] = []\n",
    "\n",
    "                all_entities[e_type] += doc.entities[e_type]\n",
    "    return all_entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseye_dev_fr_path = \"../data/newseye/v0.9/fr/HIPE-2022-newseye-v0.9-dev-fr.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the TSV into a list of `HipeDocument` objects\n",
    "newseye_dev_fr_docs = parse_tsv(file_path=newseye_dev_fr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "699"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of documents in the ajmc EN sample file\n",
    "len(newseye_dev_fr_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Path of the TSV file: ../data/newseye/v0.9/fr/HIPE-2022-newseye-v0.9-dev-fr.tsv \n",
      "Number of documents: 699 \n",
      "Number of entities: {'coarse_lit': 752, 'nested': 32} \n",
      "Number of tokens: 21727 \n",
      "Entity breakdown by type: coarse_lit\n",
      "+-----------+---------+\n",
      "|           |   count |\n",
      "+===========+=========+\n",
      "| HumanProd |      11 |\n",
      "+-----------+---------+\n",
      "| LOC       |     335 |\n",
      "+-----------+---------+\n",
      "| ORG       |     113 |\n",
      "+-----------+---------+\n",
      "| PER       |     293 |\n",
      "+-----------+---------+\n",
      "nested\n",
      "+-----------+---------+\n",
      "|           |   count |\n",
      "+===========+=========+\n",
      "| HumanProd |       1 |\n",
      "+-----------+---------+\n",
      "| LOC       |      18 |\n",
      "+-----------+---------+\n",
      "| ORG       |       7 |\n",
      "+-----------+---------+\n",
      "| PER       |       6 |\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(describe_dataset(documents=newseye_dev_fr_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect sample entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at a bunch of random entities for each entity type in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to gather all entities from documents in the dataset\n",
    "all_entities = collect_entities(newseye_dev_fr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[ORG] République (Q70802),\n",
       " [LOC] Auray  (Q62958),\n",
       " [LOC] Memel (Q161334),\n",
       " [ORG] P.T.T.  (Q3399837),\n",
       " [PER] Mes Jacquemont  (NIL)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_entities['coarse_lit'], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseye_dev_de_path =  \"../data/newseye/v0.9/de/HIPE-2022-newseye-v0.9-dev-de.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseye_dev_de_docs = parse_tsv(file_path=newseye_dev_de_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Path of the TSV file: ../data/newseye/v0.9/de/HIPE-2022-newseye-v0.9-dev-de.tsv \n",
      "Number of documents: 1124 \n",
      "Number of entities: {'coarse_lit': 539, 'nested': 29} \n",
      "Number of tokens: 40061 \n",
      "Entity breakdown by type: coarse_lit\n",
      "+-----------+---------+\n",
      "|           |   count |\n",
      "+===========+=========+\n",
      "| HumanProd |       4 |\n",
      "+-----------+---------+\n",
      "| LOC       |     263 |\n",
      "+-----------+---------+\n",
      "| ORG       |     123 |\n",
      "+-----------+---------+\n",
      "| PER       |     149 |\n",
      "+-----------+---------+\n",
      "nested\n",
      "+-----+---------+\n",
      "|     |   count |\n",
      "+=====+=========+\n",
      "| LOC |      10 |\n",
      "+-----+---------+\n",
      "| ORG |      11 |\n",
      "+-----+---------+\n",
      "| PER |       8 |\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(describe_dataset(documents=newseye_dev_de_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now have a look at a bunch of random entities for each entity type in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, we need to gather all entities from documents in the dataset\n",
    "all_entities = collect_entities(newseye_dev_de_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[scope] 3. 59) (None),\n",
       " [scope] 1. 15 § 13 (None),\n",
       " [scope] 2. 557 f.: (None),\n",
       " [work] Pk.  (Q1415903),\n",
       " [pers] Meineke  (Q77628)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_entities['coarse_lit'], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[pers.author] Aesch.  (Q40939),\n",
       " [pers.author] Sophocles  (Q11950683),\n",
       " [pers.author] Sophocles  (Q11950683),\n",
       " [scope] p. 221) (None),\n",
       " [work.primlit] Little Iliad (Q2087365)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(all_entities['fine_lit'], 5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f71d33a9884d3588e07aec0372ed71657c1daee96af90553802fa17e32b8b98"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
